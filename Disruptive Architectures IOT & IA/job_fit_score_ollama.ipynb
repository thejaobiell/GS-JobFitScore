{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faff919d",
   "metadata": {},
   "source": [
    "# JobFitScore com Ollama (local) e Fallback (Transformers/Colab)\n",
    "\n",
    "Este notebook suporta dois modos:\n",
    "\n",
    "- Modo local (Ollama): USE_OLLAMA = True. Requer o Ollama rodando em http://localhost:11434\n",
    "- Modo Colab (Fallback Transformers): USE_OLLAMA = False. Usa Hugging Face Transformers com GPU do Colab.\n",
    "\n",
    "Observação: Rodar Ollama no Colab não é recomendado. Prefira o fallback com Transformers no Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319cf0e5",
   "metadata": {},
   "source": [
    "## 1. Instalar bibliotecas necessárias (modo Colab)\n",
    "\n",
    "Execute esta célula apenas se estiver no Google Colab. No ambiente local com Ollama já instalado, não é necessário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecta se está em Colab e instala dependências se necessário\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "    !pip install -q transformers accelerate sentencepiece requests\n",
    "else:\n",
    "    print(\"Ambiente local detectado. Pulando instalação de pacotes Colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9406c",
   "metadata": {},
   "source": [
    "## 1.5 Instalar biblioteca para leitura de PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eefe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala PyPDF2 para ler PDFs (funciona tanto local quanto no Colab)\n",
    "try:\n",
    "    import PyPDF2\n",
    "    print(\"PyPDF2 já está instalado.\")\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"PyPDF2\"])\n",
    "    import PyPDF2\n",
    "    print(\"PyPDF2 instalado com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92228c7d",
   "metadata": {},
   "source": [
    "## 2. Importar bibliotecas e configurar ambiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, io, json, re\n",
    "import PyPDF2\n",
    "\n",
    "# requests pode não estar no ambiente local se não instalado\n",
    "try:\n",
    "    import requests\n",
    "except ImportError:\n",
    "    requests = None\n",
    "\n",
    "# Imports condicionais para Transformers (Colab)\n",
    "if 'IS_COLAB' in globals() and IS_COLAB:\n",
    "    from transformers import pipeline\n",
    "    from google.colab import files\n",
    "\n",
    "# Força stdout UTF-8 (especialmente em Windows)\n",
    "if hasattr(sys.stdout, 'buffer'):\n",
    "    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "\n",
    "# Flags e configurações\n",
    "USE_OLLAMA = not IS_COLAB  # Se estiver em Colab, usa fallback Transformers\n",
    "OLLAMA_URL = 'http://localhost:11434/api/generate'\n",
    "MODEL_NAME = 'llama3.2:3b'  # Ajuste para modelos maiores locais: 'gemma3:27b'\n",
    "TRANSFORMERS_MODEL = 'google/gemma-2-2b-it'  # Modelo HF para fallback\n",
    "\n",
    "print(f\"IS_COLAB={IS_COLAB} | USE_OLLAMA={USE_OLLAMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c6d6f",
   "metadata": {},
   "source": [
    "## 3. Funções auxiliares (definir antes de usar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbc16c",
   "metadata": {},
   "source": [
    "## 3.1. Funções de geração com IA (Ollama e Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_com_ollama(prompt_text: str, model: str = MODEL_NAME):\n",
    "    \"\"\"Chama a API local do Ollama e retorna texto JSON.\"\"\"\n",
    "    if requests is None:\n",
    "        raise RuntimeError(\"'requests' não disponível.\")\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"stream\": False,\n",
    "        \"format\": \"json\",\n",
    "        \"options\": {\n",
    "            \"num_ctx\": 4096,\n",
    "            \"temperature\": 0.2,\n",
    "            \"num_predict\": 800,\n",
    "        },\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(OLLAMA_URL, json=payload, timeout=180)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return data.get(\"response\", \"\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        raise ConnectionError(\"Não conectou ao Ollama. Certifique-se de que o servidor está ativo.\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        raise TimeoutError(\"Timeout: o modelo demorou para responder.\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Erro inesperado na chamada Ollama: {e}\")\n",
    "\n",
    "\n",
    "def gerar_com_transformers(prompt_text: str, model_id: str = TRANSFORMERS_MODEL):\n",
    "    \"\"\"Usa pipeline HF para gerar texto e extrair JSON.\"\"\"\n",
    "    if not IS_COLAB:\n",
    "        raise RuntimeError(\"Fallback Transformers destinado ao modo Colab.\")\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=\"auto\",\n",
    "        max_new_tokens=700,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    output = pipe(prompt_text)\n",
    "    texto = output[0][\"generated_text\"]\n",
    "    # Extrai JSON bruto (heurística simples)\n",
    "    match = re.search(r\"\\{.*\\}\\s*$\", texto, re.DOTALL)\n",
    "    if match:\n",
    "        json_text = match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_text)\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(\"Não foi possível decodificar JSON do resultado Transformers.\")\n",
    "    else:\n",
    "        raise ValueError(\"JSON não encontrado na saída do modelo Transformers.\")\n",
    "\n",
    "print(\"Funções gerar_com_ollama e gerar_com_transformers definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065582d7",
   "metadata": {},
   "source": [
    "## 3.2. Função para extrair texto de PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_texto_pdf(caminho_pdf: str) -> str:\n",
    "    \"\"\"Extrai todo o texto de um arquivo PDF.\"\"\"\n",
    "    texto_completo = \"\"\n",
    "    try:\n",
    "        with open(caminho_pdf, 'rb') as arquivo:\n",
    "            leitor = PyPDF2.PdfReader(arquivo)\n",
    "            for pagina in leitor.pages:\n",
    "                texto_completo += pagina.extract_text() + \"\\n\"\n",
    "        return texto_completo.strip()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Erro ao ler PDF: {e}\")\n",
    "\n",
    "print(\"Função extrair_texto_pdf definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6537d",
   "metadata": {},
   "source": [
    "## 3.3. Função para estruturar dados do currículo usando IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_curriculo(texto_curriculo: str) -> dict:\n",
    "    \"\"\"Usa a IA para extrair informações estruturadas do currículo.\"\"\"\n",
    "    prompt_extracao = f\"\"\"\n",
    "Analise o currículo abaixo e extraia as seguintes informações em formato JSON:\n",
    "\n",
    "{{\n",
    "  \"nome\": \"nome completo do candidato\",\n",
    "  \"habilidades\": [\"lista\", \"de\", \"habilidades\", \"técnicas\"],\n",
    "  \"experiencia\": \"resumo breve da experiência profissional em uma frase\",\n",
    "  \"cursos\": [\"lista\", \"de\", \"cursos\", \"ou\", \"certificações\"]\n",
    "}}\n",
    "\n",
    "IMPORTANTE: Retorne APENAS o JSON, sem markdown ou explicações.\n",
    "\n",
    "Currículo:\n",
    "{texto_curriculo}\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        if USE_OLLAMA:\n",
    "            resposta = gerar_com_ollama(prompt_extracao, model=MODEL_NAME)\n",
    "            candidato = json.loads(resposta)\n",
    "        else:\n",
    "            candidato = gerar_com_transformers(prompt_extracao, model_id=TRANSFORMERS_MODEL)\n",
    "        \n",
    "        # Valida campos obrigatórios\n",
    "        campos = ['nome', 'habilidades', 'experiencia', 'cursos']\n",
    "        for campo in campos:\n",
    "            if campo not in candidato:\n",
    "                raise ValueError(f\"Campo '{campo}' não encontrado no JSON extraído.\")\n",
    "        \n",
    "        return candidato\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Erro ao processar currículo: {e}\")\n",
    "\n",
    "print(\"Função processar_curriculo definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9754174",
   "metadata": {},
   "source": [
    "## 3.4. Upload de currículo (Colab) ou seleção de arquivo (local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ece0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODO DE USO:\n",
    "# - No Colab: execute esta célula e faça upload do PDF quando solicitado\n",
    "# - Local: defina CAMINHO_PDF com o caminho do arquivo PDF ou deixe None para usar dados de exemplo\n",
    "\n",
    "# Opção 1: Usar arquivo PDF do candidato\n",
    "CAMINHO_PDF = None  # Ex: \"curriculo_joao.pdf\" (local) ou None para upload no Colab\n",
    "\n",
    "# Opção 2: Usar dados de exemplo (descomente a linha abaixo para desabilitar upload)\n",
    "# USAR_DADOS_EXEMPLO = True\n",
    "\n",
    "USAR_DADOS_EXEMPLO = False\n",
    "\n",
    "if not USAR_DADOS_EXEMPLO:\n",
    "    if IS_COLAB and CAMINHO_PDF is None:\n",
    "        # Upload no Colab\n",
    "        print(\"Faça upload do currículo em PDF:\")\n",
    "        uploaded = files.upload()\n",
    "        CAMINHO_PDF = list(uploaded.keys())[0]\n",
    "        print(f\"Arquivo recebido: {CAMINHO_PDF}\")\n",
    "    elif CAMINHO_PDF is None:\n",
    "        # Local: solicita o caminho\n",
    "        CAMINHO_PDF = input(\"Digite o caminho completo do PDF do currículo: \").strip('\"').strip(\"'\")\n",
    "    \n",
    "    # Processa o PDF\n",
    "    print(f\"\\nProcessando currículo: {CAMINHO_PDF}...\")\n",
    "    texto_cv = extrair_texto_pdf(CAMINHO_PDF)\n",
    "    print(f\"Texto extraído ({len(texto_cv)} caracteres)\")\n",
    "    print(f\"\\nPrimeiros 300 caracteres:\\n{texto_cv[:300]}...\\n\")\n",
    "    \n",
    "    print(\"Extraindo informações estruturadas com IA...\")\n",
    "    candidato_novo = processar_curriculo(texto_cv)\n",
    "    print(f\"Candidato processado: {candidato_novo['nome']}\")\n",
    "    \n",
    "    # Adiciona o novo candidato à lista\n",
    "    candidatos_lista = [candidato_novo]\n",
    "else:\n",
    "    # Usa dados de exemplo\n",
    "    candidatos_lista = [\n",
    "        {\n",
    "            \"nome\": \"Ana Souza\",\n",
    "            \"habilidades\": [\"React Native\", \"JavaScript\", \"Figma\", \"UX Design\", \"Git\"],\n",
    "            \"experiencia\": \"2 anos como desenvolvedora mobile em React Native\",\n",
    "            \"cursos\": [\"React Native Avançado\", \"Design de Interfaces\"],\n",
    "        },\n",
    "        {\n",
    "            \"nome\": \"Lucas Pereira\",\n",
    "            \"habilidades\": [\"JavaScript\", \"TypeScript\", \"Node.js\", \"ReactJS\"],\n",
    "            \"experiencia\": \"3 anos como desenvolvedor full-stack, iniciando com React Native\",\n",
    "            \"cursos\": [\"ReactJS Completo\", \"APIs REST com Node.js\"],\n",
    "        },\n",
    "        {\n",
    "            \"nome\": \"Mariana Lima\",\n",
    "            \"habilidades\": [\n",
    "                \"HTML\",\n",
    "                \"CSS\",\n",
    "                \"React Native\",\n",
    "                \"APIs REST\",\n",
    "                \"Git\",\n",
    "                \"TypeScript\",\n",
    "            ],\n",
    "            \"experiencia\": \"1 ano como estagiária em desenvolvimento mobile\",\n",
    "            \"cursos\": [\"Introdução ao React Native\", \"Versionamento com Git\"],\n",
    "        },\n",
    "    ]\n",
    "    print(\"Usando dados de exemplo (3 candidatos).\")\n",
    "\n",
    "print(f\"\\nTotal de candidatos: {len(candidatos_lista)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a vaga\n",
    "vaga = {\n",
    "    \"titulo\": \"Desenvolvedor Front-End React Native\",\n",
    "    \"empresa\": \"TechFlow Solutions\",\n",
    "    \"requisitos\": [\n",
    "        \"React Native\",\n",
    "        \"JavaScript\",\n",
    "        \"TypeScript\",\n",
    "        \"APIs REST\",\n",
    "        \"Git\",\n",
    "        \"UI/UX básico\",\n",
    "    ],\n",
    "    \"descricao\": \"Responsável por desenvolver e manter aplicativos móveis usando React Native, garantindo performance e boa experiência do usuário.\",\n",
    "}\n",
    "\n",
    "# Monta o dicionário de dados completo\n",
    "dados = {\n",
    "    \"vaga\": vaga,\n",
    "    \"candidatos\": candidatos_lista  # Preenchido na célula anterior\n",
    "}\n",
    "\n",
    "print(f\"Vaga: {vaga['titulo']}\")\n",
    "print(f\"Candidatos: {len(dados['candidatos'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d13f40",
   "metadata": {},
   "source": [
    "## 4. Montagem do prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6dd36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Você é um avaliador técnico de compatibilidade entre candidatos e vagas de emprego.\n",
    "\n",
    "Analise os dados abaixo em formato JSON. Compare as habilidades, experiências e cursos dos candidatos com os requisitos da vaga.\n",
    "\n",
    "Para cada candidato, calcule um score de compatibilidade de 0 a 100 e retorne em formato JSON no seguinte modelo:\n",
    "\n",
    "{{\n",
    "  \"avaliacoes\": [\n",
    "    {{\n",
    "      \"nome\": \"Nome do candidato\",\n",
    "      \"score\": número,\n",
    "      \"feedback\": \"breve explicação sobre a pontuação\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Use os seguintes critérios:\n",
    "- + pontos para cada habilidade que coincidir com os requisitos da vaga.\n",
    "- Considere experiência e cursos relacionados como fator positivo.\n",
    "- Diminua pontos se o candidato não tiver tecnologias essenciais da vaga.\n",
    "- O score deve refletir a chance real de sucesso na vaga (0 a 100).\n",
    "\n",
    "IMPORTANTE: Retorne APENAS o JSON, sem markdown ou explicações adicionais.\n",
    "\n",
    "Dados:\n",
    "{json.dumps(dados, ensure_ascii=False, indent=2)}\n",
    "\"\"\"\n",
    "print(\"Prompt pronto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e71dfd",
   "metadata": {},
   "source": [
    "## 5. Executar avaliação e salvar resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir(resultado_dict: dict):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"VAGA: {dados['vaga']['titulo']}\")\n",
    "    print(f\"EMPRESA: {dados['vaga']['empresa']}\")\n",
    "    print(\"=\" * 60)\n",
    "    for av in resultado_dict.get('avaliacoes', []):\n",
    "        print(f\"- {av.get('nome')}\")\n",
    "        print(f\"  Score: {av.get('score')}/100\")\n",
    "        print(f\"  Feedback: {av.get('feedback')}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    if USE_OLLAMA:\n",
    "        print(f\"Usando Ollama local | Modelo: {MODEL_NAME}\")\n",
    "        saida = gerar_com_ollama(prompt, model=MODEL_NAME)\n",
    "        # Ollama retorna texto JSON; converter para dict\n",
    "        try:\n",
    "            resultado = json.loads(saida)\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(\"Resposta do Ollama não é um JSON válido.\")\n",
    "        destino = 'resultado_avaliacao_ollama.json'\n",
    "    else:\n",
    "        print(f\"Usando Transformers (Colab) | Modelo: {TRANSFORMERS_MODEL}\")\n",
    "        resultado = gerar_com_transformers(prompt, model_id=TRANSFORMERS_MODEL)\n",
    "        destino = 'resultado_avaliacao_transformers.json'\n",
    "\n",
    "    exibir(resultado)\n",
    "    with open(destino, 'w', encoding='utf-8') as f:\n",
    "        json.dump(resultado, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nResultado salvo em: {destino}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro durante a avaliação: {e}\")\n",
    "    if USE_OLLAMA:\n",
    "        print(\"Dica: verifique se o Ollama está rodando e se o modelo foi baixado (ollama list / ollama pull).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9089bf3",
   "metadata": {},
   "source": [
    "## 6. Dicas para ajuste de modelos\n",
    "\n",
    "- Modelos maiores locais: `llama3.1:8b`, `mistral:7b-instruct`, `gemma3:27b` (requer mais RAM/VRAM).\n",
    "- Em Colab, prefira: `google/gemma-2-2b-it`, `microsoft/Phi-3-mini-4k-instruct`.\n",
    "- Ajuste `num_ctx` para janelas maiores (custo de memória). Ajuste `num_predict` para limitar saída.\n",
    "- Reduza `temperature` para respostas mais consistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c9e4d",
   "metadata": {},
   "source": [
    "## 7. Como usar com seu próprio currículo\n",
    "\n",
    "### Modo Local (Windows/macOS/Linux):\n",
    "1. Salve seu currículo como PDF (ex: `meu_curriculo.pdf`)\n",
    "2. Na célula \"3.4. Upload de currículo\", defina:\n",
    "   ```python\n",
    "   CAMINHO_PDF = \"C:/caminho/completo/meu_curriculo.pdf\"\n",
    "   USAR_DADOS_EXEMPLO = False\n",
    "   ```\n",
    "3. Execute todas as células na ordem\n",
    "\n",
    "### Modo Colab:\n",
    "1. Execute as células 1, 1.5, 2 e 3.1 primeiro\n",
    "2. Na célula \"3.4. Upload de currículo\", defina:\n",
    "   ```python\n",
    "   USAR_DADOS_EXEMPLO = False\n",
    "   ```\n",
    "3. Execute a célula - aparecerá um botão de upload\n",
    "4. Selecione seu PDF\n",
    "5. Continue executando as células seguintes\n",
    "\n",
    "### Para testar com dados de exemplo:\n",
    "```python\n",
    "USAR_DADOS_EXEMPLO = True\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
